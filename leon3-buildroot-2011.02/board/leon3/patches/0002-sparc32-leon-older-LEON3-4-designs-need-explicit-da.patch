From d692c272be9f4b3e1fd9dc231579bb8da246f941 Mon Sep 17 00:00:00 2001
From: Daniel Hellstrom <daniel@gaisler.com>
Date: Wed, 2 Feb 2011 11:55:35 +0100
Subject: [PATCH 2/9] sparc32,leon: older LEON3/4 designs need explicit data cache miss on swap/ldst

We need to use SWAPA/LDST*A with ASI=1 in order to force a data
cache miss on older LEON3/4 systems (eASIC for example need it).

Without this patch older systems will end up in deadlock
in spinlocks rather fast.

Signed-off-by: Daniel Hellstrom <daniel@gaisler.com>
---
 arch/sparc/include/asm/smpprim.h     |    4 ++
 arch/sparc/include/asm/spinlock_32.h |   61 +++++++++++++++++++++++++++++++++-
 arch/sparc/include/asm/system_32.h   |    4 ++
 arch/sparc/lib/atomic_32.S           |   10 +++++
 arch/sparc/lib/locks.S               |   16 +++++++++
 arch/sparc/mm/srmmu.c                |    4 ++
 6 files changed, 98 insertions(+), 1 deletions(-)

diff --git a/arch/sparc/include/asm/smpprim.h b/arch/sparc/include/asm/smpprim.h
index eb849d8..0348801 100644
--- a/arch/sparc/include/asm/smpprim.h
+++ b/arch/sparc/include/asm/smpprim.h
@@ -19,7 +19,11 @@ static inline __volatile__ char test_and_set(void *addr)
 {
 	char state = 0;
 
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	__asm__ __volatile__("ldstub [%0], %1         ! test_and_set\n\t"
+#else			     
+	__asm__ __volatile__("ldstuba [%0] 1, %1        ! test_and_set\n\t" /* ASI_LEON23_DCACHE_MISS */
+#endif			     
 			     "=r" (addr), "=r" (state) :
 			     "0" (addr), "1" (state) : "memory");
 
diff --git a/arch/sparc/include/asm/spinlock_32.h b/arch/sparc/include/asm/spinlock_32.h
index 5f5b8bf..bb9dea1 100644
--- a/arch/sparc/include/asm/spinlock_32.h
+++ b/arch/sparc/include/asm/spinlock_32.h
@@ -20,7 +20,11 @@ static inline void arch_spin_lock(arch_spinlock_t *lock)
 {
 	__asm__ __volatile__(
 	"\n1:\n\t"
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	"ldstub	[%0], %%g2\n\t"
+#else
+	"ldstuba	[%0] 1, %%g2\n\t" /* ASI_LEON23_DCACHE_MISS */
+#endif
 	"orcc	%%g2, 0x0, %%g0\n\t"
 	"bne,a	2f\n\t"
 	" ldub	[%0], %%g2\n\t"
@@ -39,7 +43,11 @@ static inline void arch_spin_lock(arch_spinlock_t *lock)
 static inline int arch_spin_trylock(arch_spinlock_t *lock)
 {
 	unsigned int result;
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	__asm__ __volatile__("ldstub [%1], %0"
+#else
+	__asm__ __volatile__("ldstuba [%1] 1, %0" /* ASI_LEON23_DCACHE_MISS */
+#endif
 			     : "=r" (result)
 			     : "r" (lock)
 			     : "memory");
@@ -81,6 +89,7 @@ static inline void __arch_read_lock(arch_rwlock_t *rw)
 {
 	register arch_rwlock_t *lp asm("g1");
 	lp = rw;
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	__asm__ __volatile__(
 	"mov	%%o7, %%g4\n\t"
 	"call	___rw_read_enter\n\t"
@@ -88,6 +97,16 @@ static inline void __arch_read_lock(arch_rwlock_t *rw)
 	: /* no outputs */
 	: "r" (lp)
 	: "g2", "g4", "memory", "cc");
+#else
+	__asm__ __volatile__(
+	"mov	%%o7, %%g4\n\t"
+	"set	3, %%g3\n\t" /* ___rw_read_enter assumes g3 is three! */
+	"call	___rw_read_enter\n\t"
+	" ldstuba	[%%g1 + %%g3]1, %%g2\n"  /* ASI_LEON23_DCACHE_MISS */
+	: /* no outputs */
+	: "r" (lp)
+	: "g2", "g3", "g4", "memory", "cc");
+#endif
 }
 
 #define arch_read_lock(lock) \
@@ -101,6 +120,7 @@ static inline void __arch_read_unlock(arch_rwlock_t *rw)
 {
 	register arch_rwlock_t *lp asm("g1");
 	lp = rw;
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	__asm__ __volatile__(
 	"mov	%%o7, %%g4\n\t"
 	"call	___rw_read_exit\n\t"
@@ -108,6 +128,16 @@ static inline void __arch_read_unlock(arch_rwlock_t *rw)
 	: /* no outputs */
 	: "r" (lp)
 	: "g2", "g4", "memory", "cc");
+#else
+	__asm__ __volatile__(
+	"mov	%%o7, %%g4\n\t"
+	"set	3, %%g3\n\t" /* ___rw_read_exit assumes g3 is three! */
+	"call	___rw_read_exit\n\t"
+	" ldstuba	[%%g1 + %%g3] 1, %%g2\n" /* ASI_LEON23_DCACHE_MISS */
+	: /* no outputs */
+	: "r" (lp)
+	: "g2", "g3", "g4", "memory", "cc");
+#endif
 }
 
 #define arch_read_unlock(lock) \
@@ -121,6 +151,7 @@ static inline void arch_write_lock(arch_rwlock_t *rw)
 {
 	register arch_rwlock_t *lp asm("g1");
 	lp = rw;
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	__asm__ __volatile__(
 	"mov	%%o7, %%g4\n\t"
 	"call	___rw_write_enter\n\t"
@@ -128,6 +159,16 @@ static inline void arch_write_lock(arch_rwlock_t *rw)
 	: /* no outputs */
 	: "r" (lp)
 	: "g2", "g4", "memory", "cc");
+#else
+	__asm__ __volatile__(
+	"mov	%%o7, %%g4\n\t"
+	"set	3, %%g3\n\t" /* ___rw_write_enter assumes g3 is three! */
+	"call	___rw_write_enter\n\t"
+	" ldstuba	[%%g1 + %%g3] 1, %%g2\n" /* ASI_LEON23_DCACHE_MISS */
+	: /* no outputs */
+	: "r" (lp)
+	: "g2", "g3", "g4", "memory", "cc");
+#endif
 	*(volatile __u32 *)&lp->lock = ~0U;
 }
 
@@ -135,11 +176,18 @@ static inline int arch_write_trylock(arch_rwlock_t *rw)
 {
 	unsigned int val;
 
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	__asm__ __volatile__("ldstub [%1 + 3], %0"
 			     : "=r" (val)
 			     : "r" (&rw->lock)
 			     : "memory");
-
+#else
+	__asm__ __volatile__("set	3, %%g3\n\t"
+			     "ldstuba [%1 + %%g3] 1, %0" /* 1=ASI DCACHE_MISS */
+			     : "=r" (val)
+			     : "r" (&rw->lock)
+			     : "g3", "memory");
+#endif
 	if (val == 0) {
 		val = rw->lock & ~0xff;
 		if (val)
@@ -156,6 +204,7 @@ static inline int __arch_read_trylock(arch_rwlock_t *rw)
 	register arch_rwlock_t *lp asm("g1");
 	register int res asm("o0");
 	lp = rw;
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	__asm__ __volatile__(
 	"mov	%%o7, %%g4\n\t"
 	"call	___rw_read_try\n\t"
@@ -163,6 +212,16 @@ static inline int __arch_read_trylock(arch_rwlock_t *rw)
 	: "=r" (res)
 	: "r" (lp)
 	: "g2", "g4", "memory", "cc");
+#else
+	__asm__ __volatile__(
+	"mov	%%o7, %%g4\n\t"
+	"set 3, %%g3\n\t" /* __rw_read_try assumes g3 is three! */
+	"call	___rw_read_try\n\t"
+	" ldstuba	[%%g1 + %%g3] 1, %%g2\n" /* 1=ASI DCACHE_MISS */
+	: "=r" (res)
+	: "r" (lp)
+	: "g2", "g3", "g4", "memory", "cc");
+#endif
 	return res;
 }
 
diff --git a/arch/sparc/include/asm/system_32.h b/arch/sparc/include/asm/system_32.h
index aba1609..66ba03d 100644
--- a/arch/sparc/include/asm/system_32.h
+++ b/arch/sparc/include/asm/system_32.h
@@ -185,7 +185,11 @@ BTFIXUPDEF_CALL(void, ___xchg32, void)
 static inline unsigned long xchg_u32(__volatile__ unsigned long *m, unsigned long val)
 {
 #ifdef CONFIG_SMP
+#ifndef CONFIG_SPARC_LEON
 	__asm__ __volatile__("swap [%2], %0"
+#else
+	__asm__ __volatile__("swapa [%2] 1, %0"
+#endif
 			     : "=&r" (val)
 			     : "0" (val), "r" (m)
 			     : "memory");
diff --git a/arch/sparc/lib/atomic_32.S b/arch/sparc/lib/atomic_32.S
index 178cbb8..afde974 100644
--- a/arch/sparc/lib/atomic_32.S
+++ b/arch/sparc/lib/atomic_32.S
@@ -51,7 +51,12 @@ ___atomic24_add:
 	wr	%g7, 0x0, %psr		! Set %psr
 	nop; nop; nop;			! Let the bits set
 #ifdef CONFIG_SMP
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 1:	ldstub	[%g1 + 3], %g7		! Spin on the byte lock for SMP.
+#else
+1:	set	3, %g7
+	ldstuba	[%g1 + %g7] 1, %g7	! 1 = ASI Force cache miss on LEON
+#endif
 	orcc	%g7, 0x0, %g0		! Did we get it?
 	bne	1b			! Nope...
 	 ld	[%g1], %g7		! Load locked atomic24_t
@@ -77,7 +82,12 @@ ___atomic24_sub:
 	wr	%g7, 0x0, %psr		! Set %psr
 	nop; nop; nop;			! Let the bits set
 #ifdef CONFIG_SMP
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 1:	ldstub	[%g1 + 3], %g7		! Spin on the byte lock for SMP.
+#else
+1:	set	3, %g7
+	ldstuba	[%g1 + %g7] 1, %g7	! 1 = ASI Force cache miss on LEON
+#endif
 	orcc	%g7, 0x0, %g0		! Did we get it?
 	bne	1b			! Nope...
 	 ld	[%g1], %g7		! Load locked atomic24_t
diff --git a/arch/sparc/lib/locks.S b/arch/sparc/lib/locks.S
index 64f53f2..578b2de 100644
--- a/arch/sparc/lib/locks.S
+++ b/arch/sparc/lib/locks.S
@@ -22,13 +22,21 @@
 ___rw_read_enter_spin_on_wlock:
 	orcc	%g2, 0x0, %g0
 	be,a	___rw_read_enter
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	 ldstub	[%g1 + 3], %g2
+#else
+	 ldstuba	[%g1 + %g3]1, %g2 /* ASI_LEON23_DCACHE_MISS, g3=3 */
+#endif
 	b	___rw_read_enter_spin_on_wlock
 	 ldub	[%g1 + 3], %g2
 ___rw_read_try_spin_on_wlock:
 	andcc	%g2, 0xff, %g0
 	be,a	___rw_read_try
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	 ldstub	[%g1 + 3], %g2
+#else
+	 ldstuba	[%g1 + %g3]1, %g2 /* ASI_LEON23_DCACHE_MISS, g3=3 */
+#endif
 	xnorcc	%g2, 0x0, %o0	/* if g2 is ~0, set o0 to 0 and bugger off */
 	bne,a	___rw_read_enter_spin_on_wlock
 	 ld	[%g1], %g2
@@ -37,13 +45,21 @@ ___rw_read_try_spin_on_wlock:
 ___rw_read_exit_spin_on_wlock:
 	orcc	%g2, 0x0, %g0
 	be,a	___rw_read_exit
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	 ldstub	[%g1 + 3], %g2
+#else
+	 ldstuba	[%g1 + %g3]1, %g2 /* ASI_LEON23_DCACHE_MISS, g3=3 */
+#endif
 	b	___rw_read_exit_spin_on_wlock
 	 ldub	[%g1 + 3], %g2
 ___rw_write_enter_spin_on_wlock:
 	orcc	%g2, 0x0, %g0
 	be,a	___rw_write_enter
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	 ldstub	[%g1 + 3], %g2
+#else
+	 ldstuba	[%g1 + %g3]1, %g2 /* ASI_LEON23_DCACHE_MISS, g3=3 */
+#endif
 	b	___rw_write_enter_spin_on_wlock
 	 ld	[%g1], %g2
 
diff --git a/arch/sparc/mm/srmmu.c b/arch/sparc/mm/srmmu.c
index cbef74e..678b693 100644
--- a/arch/sparc/mm/srmmu.c
+++ b/arch/sparc/mm/srmmu.c
@@ -98,7 +98,11 @@ static int is_hypersparc;
  */
 static inline unsigned long srmmu_swap(unsigned long *addr, unsigned long value)
 {
+#if !(defined(CONFIG_SPARC_LEON) && defined(CONFIG_SMP))
 	__asm__ __volatile__("swap [%2], %0" : "=&r" (value) : "0" (value), "r" (addr));
+#else
+	__asm__ __volatile__("swapa [%2] 1, %0" : "=&r" (value) : "0" (value), "r" (addr));
+#endif
 	return value;
 }
 
-- 
1.5.4

